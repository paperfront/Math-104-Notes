\section{Topology Part 2 - Electric Boogaloo}
We will now expand upon the concept of metric spaces that we covered in \ref{defn:metric_space}. The basis of most topological concepts we will cover are derived from the  definitions of open and closed sets in the following section. 
\subsection{Open Sets}
A helpful tool for understanding open and closed sets will be the idea of an 'open ball'. This name will be justified after we have defined what an open set is.
\begin{defn}{Open Ball}{open_ball}
For some metric space \((S, d)\), \(x\in S\), \(r > 0\),
\begin{displaymath}
  B_r(x) := \{y \in S: d(x,y) < r\} \subseteq S
\end{displaymath}
I will sometimes refer to this concept as an 'epsilon ball', since we will often be considering very small values of \(r\). Thus, we can have an equivalent definition by replacing \(r\) with \(\epsilon\).
\end{defn}

\begin{exmp}{}{}
\((\R, d_{std})\): \(B_1(3) = (2,4)\) where \((2,4)\) is the open interval between 2 and 4.
\end{exmp}
\begin{exmp}{}{}
\((\R^2, d_{std})\): \(B_2((0, 0)) = \{(x, y) \in \R^2: x^2 + y^2 < 4\}\). Note that this is a circle of radius 2 centered at the origin.
\end{exmp}

The reason we call this a ball is because of how we can visualize this set in the metric spaces of \((\R^2,d_{std})\) and \((\R^3, d_{std})\). In \((\R^2,d_{std})\), we can visualize the epsilon ball as the circle of radius \(r\) centered at \(x\). Similarly, in \(\R^3\) we can visualize this as a sphere of radius \(r\) centered at \(x\). In general, one can think of the open ball in \(\R^k\) as being a k-dimensional sphere. Another detail to note is that we need not be working with a metric space of the form \((\R^k, d_{std})\) for the open ball to be useful. We simply reference \(\R^k\) in examples since it is easiest to visualize. 
\newline

 

\begin{defn}{Open Set}{open_set}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). 
\newline
\(E \subseteq S\) is open if for all \(x \in E\), there \textbf{\textit{exists}} some \(r > 0\) such that \(B_r(x) \subseteq E\).

\end{defn}
%TODO insert open set diagram
The important take away from the above definition is that for any point \(x \in E\), we just need to be able to find 1 value of \(r\) that can be as small as we like such that the ball centered at \(x\) of radius \(r\) is contained entirely within \(E\). 
\newline

\begin{exmp}{}{}
\([0, 1] \subseteq \R\) is not open. Consider the epsilon ball \(B_r(0) = (-r, r) \not\subseteq [0,1]\) since \(-r < 0\) and the interval \([0, 1]\) contains no numbers less than 0.
\end{exmp}

\begin{exmp}{}{}
\((0, 1) \subseteq \R\) is open. To show that this is open, consider any point \(x\in (0, 1)\). Your task is to find some \(r\) small enough such that \(B_r(x)\) is entirely contained within \((0, 1)\). Remember that \(r\) can be expressed in terms of \(x\). It may also be helpful to consider the fact that \(B_r(x)= (x - r, x + r)\).
\end{exmp}
\begin{exmp}{}{S_is_open}
Let \((S, d)\) be a metric space. \(S\) is open, and \(\emptyset\) is open (reminder that \(\emptyset\) is the empty set). To see why \(S\) is open, consider any point \(x \in S\). The epsilon ball \(B_r(x)\) can only contain points in defining set of the metric space \(S\), and so \(B_r(x) \subseteq S\). Thus, \(S\) is open. We say that the empty set is trivially open because there are no elements in it, and so no such epsilon balls can be constructed on the empty set.
\end{exmp}
The following theorem will be proven very explicitly to help build some intuition with open sets. Subsequent proofs will not be broken down as deeply.
\newline
\begin{thm}{}{}
Let \((S, d)\) be a metric space. For any \(x \in S\), and for any \(r > 0\), \(B_r(x)\) is an open subset in \(S\).
\newline
\newline 
To prove this statement, we must show that for any \(y \in B_r(x)\), we can find some \(s > 0\) such that \(B_s(y) \subseteq B_r(x)\). We can think of this intuitively as follows: the point \(y\) must be at some distance \(d < r\) away from \(x\). Thus, we know that we can find points between \(y\) and the border of \(B_r(x)\) by considering those points that are of distance \(r - d\) away from \(y\). So, we let \(s = d - r\). Thus, the maximum distance of any point in \(B_s(y)\) from \(x\) will be \(< d + s = d + (r - d) = r\), and so this point will also lie in \(B_r(x)\). Remember that to show \(B_s(y) \subseteq B_r(x)\), it is sufficient to show that \(a \in B_s(y) \implies a \in B_r(x)\). We can formalize our intuition by using the triangle inequality and the following diagram:
	%TODO Insert diagram for showing epsilon ball is an open subset
\begin{proof}
	For any \(y \in S\), define \(D := d(x, y) < r\), and \(s := r - D > 0\). Consider some \(z \in B_s(y)\).
	\begin{equation*}
  		d(x,z) \leq d(x,y) + d(y,z) = D + d(y,z) < D + s = r
	\end{equation*}
	This implies that \(B_s(y) \subseteq B_r(x)\), and since \(y \in S\) is arbitrary, we have shown that \(B_r(x)\) is open.

\end{proof}
\end{thm}

\begin{thm}{}{union_of_open_sets_is_open}

Let \((S, d)\) be a metric space. Let \(U\) be a collection of open sets (of potentially infinite size): \(U = \{u_i : i \in I\}\). Then,
	\begin{equation*}
  		\bigcup_{i \in I}u_i \textrm{ is open.}
	\end{equation*}
In other words, the union of any collection of open sets is an open set.
\newline 

Intuitively, we can consider the fact that for any element x in one of the open sets \(u_i\), there will exist \(r > 0\) such that the epsilon ball of radius \(r\) is also contained in \(u_i\) since it is given that each \(u_i\) is open. Thus, since the epsilon ball is contained in \(u_i\), that same epsilon ball must also be contained in the union of all the \(u_i\). This is true since no elements are lost when unioning a collection of sets. Thus, since an epsilon ball exists for any element in the union of the \(u_i\), it follows by definition that the the union of the \(u_i\) is also an open set.
\begin{proof}
Consider any \(x \in \bigcup_{i \in I}u_i\). We can infer that there exists some \textit{i} such that \(x \in u_i\). Since \(u_i\) is open, there exists \(r > 0\) such that \(B_r(x) \subseteq u_i\). Thus, it follows that \(B_r(x) \subseteq \bigcup_{i \in I}u_i\). Since our choice of \(x\) was arbitrary, this logic must hold for all \(x \in \bigcup_{i \in I}u_i\). Thus, \(\bigcup_{i \in I}u_i\) is an open set.
\end{proof}

\end{thm}
The following is also worth noting: \newline 
\begin{exmp}{}{}
In the metric space \((\R, d_{std})\):
\begin{itemize}
  \item For \(a \leq b \in \R\), the open interval \((a, b)\) is an open set.
  \item For \(a \in \R\), the open intervals \((- \infty, a)\), and \((a, \infty)\) are open sets.
  \item For \(a \leq b \in \R\), the intervals \([a, b)\), \((a, b]\), and \([a, b]\) are \textbf{not} open sets.
\end{itemize}
These results can easily be proven by using similar logic to that of example 3. Try thinking them through!
\end{exmp}



\subsection{Closed Sets}
%TODO Intersection of closed sets is closed
Naively, one may think that a closed set is simply a set that is not open. However, the definition of a closed set differs slightly from this, which may seem a bit counter intuitive. Instead, we chose to call a set closed if its \textit{complement} is open. This means that it is possible to have a set that is both open and closed, or a set that is not open and not closed (some examples will be discussed later).
\newline

\begin{defn}{Closed Set}{}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). \newline 
\(E\) is \textbf{closed} if \(E^C\) is \textit{open}.
\newline 

Remember that \(E^C\) is called the \textit{complement} of \(E\), and is defined as \(E^c := \{x \in S : x \not \in E\}\).
\end{defn}
\begin{exmp}{}{}
\([0, 1] \subseteq \R\) is closed. Since a closed set is defined by whether its complement is open, we must consider \([0,1]^C = (- \infty, 0) \cup (1,  \infty)\). As seen in example 5, both \((- \infty, 0)\) and \((1, \infty)\) are open, and by theorem \ref{thm:union_of_open_sets_is_open}, the union of open sets is also an open set. Thus, \([0,1]^C\) is open, and so \([0,1]\) is closed. Similarly, it can be shown that for any \(a<b \in \R\), the closed interval \([a,b]\) is also a closed set.
\end{exmp}
\begin{exmp}{}{}
\((0, 1) \subseteq \R\) is not closed. \((0, 1)^C = (-\infty, 0] \cup [1, \infty)\), which is not open (seen by considering an epsilon ball centered at 0 or 1: \(B_r(0)\) or \(B_r(1)\)). Since \((0, 1)^C\) is not open, \((0, 1)\) is not closed.
\end{exmp}
\begin{exmp}{}{}
\(S\) is both open \textbf{and} closed and \(\emptyset\) is both open \textbf{and} closed. We already showed in example \ref{exmp:S_is_open} that \(S\) is open and \(\emptyset\) is open. Note that \(S^C = \emptyset\) and \(\emptyset^C = S\). Thus, it follows that \(S\) and \(\emptyset\) are also closed.
\end{exmp}
\begin{exmp}{}{limit_point_intro}
\(E = \{ \frac{1}{n} : n \in \N \} \subseteq \R\) is not closed. \begin{proof}
\(0 \not \in E \implies 0 \in E^C\). For any \(r > 0\), there must exist \(x \in E\) such that \(x \in B_r(0)\). This follows because the sequence \((\frac{1}{n})\) converges to 0, and so the sequence will get within \(\epsilon\) of 0 for any \(\epsilon > 0\). In other words, \(B_r(0) \cap E \not = \emptyset\). This implies that \(B_r(0)\) is not entirely contained within \(E^C\), and so \(E^C\) is not open. Thus, \(E\) is not closed.
\end{proof}

\end{exmp}





\subsection{Closure}
Please carefully review example \ref{exmp:limit_point_intro}, as this will motivate our coming discussion of limit points. Note what we observed: we had a sequence contained within \(E\) that converged to a value that was not in \(E\). This led us to conclude that \(E\) was not closed, since any epsilon ball centered at the convergent point must contain a point in \(E\) by definition of convergent sequence. Thus, no epsilon ball centered at the convergent point can be contained entirely inside \(E^C\), which means \(E^C\) cannot be an open set. This shows that \(E\) is not closed. 
\begin{defn}{Limit Point}{limit_point}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). We say \(x \in S\) is a \textit{limit point} of E if for all \(r > 0\), \(B_r(x) \cap E\) contains some point \(y \in S\) such that \(x \not = y\). Here are some equivalent formulations of this idea:
	\begin{itemize}
  		\item \(E\) contains points arbitrarily close to \(x\) that are not equal to \(x\).  
  		\item For any \(\epsilon > 0\), one can find \(y \in E\) such that \(y \in B_{\epsilon}(x)\) and \(x \not = y\)
  		\item There exists a sequence \((s_n)\) where each \(s_n \in E\) that converges to \(x\) and \(s_n\) is not constant valued (such as \(s_n = x\) for all n).
	\end{itemize}
The following two remarks are also important to keep in mind: 
\begin{itemize}
  \item It is possible for a limit point of \(E\) to not be an element of \(E\). For example, \(E = (0, 1) \subseteq \R\) has a limit point of 0 and a limit point of 1, but neither is contained within \(E\).
  \item It is possible that a point in \(E\) is \textbf{not} a limit point of E. For example, consider example \ref{exmp:limit_point_intro}. \(1 \in E\), but 1 is not a limit point of \(E\) since \(B_{\frac{1}{4}} \cap E = \{1\}\), and so since the intersection does not contain any values besides 1, we know that 1 is not a limit point of \(E\) by definition. 
\end{itemize}


\end{defn}
\begin{defn}{Closure}{closure}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). The \textit{closure} of \(E\) is written as \(\overline{E}\). 
\begin{equation*}
  \overline{E} := E \cup \{\textrm{limit points of E}\}
\end{equation*}

\end{defn}


%TODO Show that a corollary to this is that the smallest closed set containing A is its closure
\begin{thm}{}{}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). \newline 

\(E\) is closed \(\iff\) \(E = \overline{E}\) \newline 

For intuition of the forward direction, we notice that if a subset is closed but doesn't contain all of its limit points, we will be able to arrive at a contradiction by the same reasoning above. Thus, we will be able to show that a closed set must contain all of its limit points, and thus be equal to its closure.\newline

For the reverse direction, consider why we began our discussion of limit points. We saw that if there were any limit points of our subset that were not contained in our subset, then the complement of our subset would never be open, and so our subset would never be closed. However, if our subset contained all of its limit points, then the complement should be open, meaning that our subset will be closed. We will now formalize both of these proofs. \newline 

Forward Direction:
\begin{proof}
Assume \(E\) is a closed subset. Showing that \(E\) is equal to its closure is equivalent to showing that \(E\) contains all of its limit points. This is equivalent to showing that no limit points of \(E\) are in \(E^C\). Consider some limit point of \(E\), \(x \in S\). By definition of limit point, \(B_r(x) \cap E \not = \emptyset\) for all \(r > 0\). Since \(E\) is closed, \(E^C\) is open. Since \(E^C\) is open, it cannot contain the point \(x\) since \(B_r(x)\not\subseteq E^C\) for any \(r > 0\). Finally, \(x \not\in E^C \implies x \in E\). Since the limit point \(x\) is arbitrary, \(E\) contains all of its limit points.
\end{proof}
Reverse Direction: 
\begin{proof}
Assume \(E = \overline{E}\). To show \(E\) is closed, we must show \(E^C\) is open. Consider any \(x \in E^C\). Since \(E\) contains all of its limit points, we know that \(x\) is not a limit point of \(E\). This implies that \(B_r(x) \cap E = \emptyset \textrm{ or } \{x\}\) for some \(r > 0\). However, by assumption \(x \not\in E\), so \(B_r(x) \cap E = \emptyset\). Thus, \(B_r(x)\) must be contained entirely in \(E^C\), and so \(E^C\) is open. This implies \(E\) is closed.
\end{proof}
\end{thm}
\begin{exmp}{}{}
\(E = \{ \frac{1}{n} : n \in \N \} \cup \{0\} \subseteq \R\) is closed. We first notice that the only limit point of \(\{ \frac{1}{n} : n \in \N \}\) is 0, and so \(E\) contains all of its limit points. Thus, \(E\) is closed.
\end{exmp}



\subsection{Compact Subsets}
\begin{defn}{Open Covers and Finite Subcovers}{open_cover}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). Let \(\{u_i : i \in I\}\) be a collection of open subsets of \(S\).
\begin{itemize}
  \item \(\{u_i : i \in I\}\) is called an \textbf{open cover} of \(E\) if: 
  	\begin{equation*}
  		E \subseteq \bigcup_{i \in I}u_i
	\end{equation*}
	Equivalently, for any \(x \in E\), there exists \(i \in I\) such that \(x \in u_i\). In words: the union of the open sets contains all of \(E\).
  \item We say an open cover has a \textbf{finite subcover} if there exist finitely many \(i_1, i_2, \dots,i_n\) such that \(E \subseteq \bigcup_{k = 1}^n u_{i_k}\).
\end{itemize}

\end{defn}

\begin{defn}{Compact Subset}{compact_subset}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). \newline 
\(E\) is a \textbf{compact} subset if \textbf{\textit{every}} open cover of \(E\) has a \textit{finite subcover}.
	\newline 
	
	This definition should make it easy to show that a subset is not compact. We only have to find 1 example of an open cover of \(E\) that has \textbf{no} finite subcover to show that \(E\) is not compact.
\end{defn}
\begin{exmp}{}{}
\(\N = \{1, 2, 3, \dots\} \subseteq \R\) is not compact. We can show this by finding some open cover of \(\N\) that has no finite subcover. Since \(\N\) is of infinite size, it shouldn't be hard to create an open cover that requires infinitely many sets to cover all of \(\N\). For example, consider \(\{u_n = (n - \frac{1}{2}, n + \frac{1}{2}) : n \in N\}\). Each \(u_n\) is open, and for any \(x \in \N\), we know that \(x \in u_x\) by construction (if this is not immediately clear, try plugging in \(x\) to \(u_x\)). However, any finite collection of these \(u_n\) must have some largest value of \(n\). This means that \(u_{n+1}\) is not in the finite collection, and so \(n + 1\) is not in the union of the finite collection. Thus, no finite cover can exist for this open cover. 
\end{exmp}
\begin{exmp}{}{}
\(E = \{ \frac{1}{n} : n \in \N \} \cup \{0\} \subseteq \R\) is compact. Consider any open cover \(\{u_i : i \in I\}\). Since \(0 \in E\), there must exist \(i \in I\) such that \(0 \in u_i\). Since \(u_i\) is open, there exists \(r > 0\) such that \(B_r(0) \subseteq u_i\). Equivalently, \(u_i\) contains the set \(\{\frac{1}{n} : n > \frac{1}{r}\}\) (this follows from the fact that the values of \(\frac{1}{n}\) that are in \(B_r(0)\) satisfy \(d(\frac{1}{n}, 0) < r\) which means \(\frac{1}{n} < r\)). Note that \(\{ \frac{1}{n} : n \in \N \} = \{ \frac{1}{n} : 1 \leq n \leq \frac{1}{r} \} \cup \{ \frac{1}{n} : n > \frac{1}{r}\}\), and the term on the left of the union has finitely many values of n (since \(r > 0\) is finite), and the term on the right of the union takes on infinitely many values of n. We now want to make use of the fact that there are only finitely many values of \(\frac{1}{n}\) for \(1 \leq n \leq \frac{1}{r}\). Since there are finitely many values, and each value must be covered by at least one \(u_k\), it follows that there must be a finite number of \(u_k\) that cover these values. Finally, we can construct a finite subcover by taking each \(u_k\) along with the \(u_i\) we chose earlier. Thus, any open cover of \(E\) has a finite subcover, and so \(E\) is compact.
\end{exmp}

%TODO Try to explain intuition for why certain sets are compact and others are not, to prepare for the implication that compact sets are closed and bounded. Need to give more examples, and give commentary on each example.


%TODO Define sequentially compact
\begin{defn}{Sequentialy Compact}{sequentially_compact}
Let \((S, d)\) be a metric space. A subset \(E \subseteq S\) is called \textbf{sequentially compact} if for all sequences of points in \(E\), there is a subsequence that converges to a point in \(E\). See definition \ref{defn:metric_space_sequence_convergence} to review convergence of sequences in metric spaces.
\newline 

Note that this definition sounds somewhat similar to the definition of a closed subset, but we must be very careful to understand the difference. Earlier we showed that a subset \(E\)
 is closed if it contains all of its limit points. In other words, every sequence of points in \(E\) that converges (if any exist) must converge to a point in \(E\). However, the definition of sequentially compact is even stronger. It requires that \textbf{\textit{any}} sequence of points in \(E\) (whether or not the sequence converges is irrelevant) \textbf{MUST} have a subsequence that converges to a point in \(E\). Soon, we will prove that sequentially compact is a stronger statement than closedness: i.e. sequentially compact \(\implies\) closed. Moreover, similar intuition can be found when considering if compact subsets are bounded. If a subset were to be unbounded, then any sequence in that subset would diverge to infinity, and thus so would every subsequence. This would mean that our subset could not be sequentially compact. By contrapositive, we will find that sequentially compact\(\implies\) bounded
 \end{defn}
\begin{exmp}{}{}
Consider \(E = (0, 1) \subseteq \R\). \(E\) is \textbf{not} sequentially compact. Consider the sequence \((1, \frac{1}{2}, \frac{1}{3}, \dots)\). Since this sequence converges to 0, all of its subsequences must also converge to 0. However, \(0 \not \in E\), so \(E\) is not sequentially compact.
\end{exmp}
\subsection{Heine-Borel}
In this section, we will be building up to a big BANG with the Heine-Borel theorem. Heine-Borel tells us that if we are working in \((\R^k, d_{std})\), then closed and bounded \(\implies\) sequentially compact. However, before we get there, we will also prove the following results for any metric space:
	\begin{equation*}
  		\textrm{compact \(\iff\) sequentially compact \(\implies\) closed and bounded}
	\end{equation*}
Let us begin our proof journey!
\begin{thm}{}{}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). \newline 
If \(E\) is compact, then \(E\) is closed.\newline
The intuition on this proof may be a little bit strange. As we saw above, we can more easily show that a sequentially compact set is closed, and since we will soon be proving that compact is equivalent to sequentially compact, we could choose to delay this proof. Instead, this proof is left in the notes to help the reader gain familiarity in working with compact subsets. \newline 

So, why would we expect a compact subset to be closed? We start by noticing that if a subset were not closed, then it must not contain at least one of its limit points. Thus, there exist some sequence in the subset that converges to a point not in the subset. We can imagine constructing an open cover where each subset is very very small, and approaching the limit point. Since this open cover would require an infinite amount of subsets to cover this, the subset cannot be compact. In other words, there is a very strong connection between compactness and limit points.\newline 

While we could construct a proof by contraposition, it is more helpful to see a direct proof. The intuition for the following proof is as follows: To show our subset E is closed, we must show its complement is open. So, we start by considering a point x in the complement. If we knew that E had a finite number of elements, then we could simply pick the point that was closest to x, call the distance between them d, and create an epsilon ball of radius \(\frac{d}{2}\) centered at x. Since d is the distance between x and the closest point to x inside of E, we know that this epsilon ball must be entirely contained in the complement as desired. However, we cannot assume that E has a finite number of elements. Instead, we know that E has a finite subcover. We can now cleverly construct our subcover so that each subset in the cover will be an epsilon ball centered at an element of E. Then, by assumption of compactness, we can find a finite number of these epsilon balls that cover E. Then, we can show that there exists some closest epsilon ball to x, and show that the two epsilon balls do not intersect (by clever selection of the radii). \newline 

\begin{proof}
Consider some \(x \in E^C\). For any \(y \in E\), let \(r_y = \frac{1}{2} d(x,y)\). Consider the following open cover of E: \(\{B_{r_y}(y) : y \in E\}\). Since E is compact, a finite subcover exists. Let this subcover be \(\{B_{r_{y_i}}(y_i) : 1 \leq i \leq n \}\). Let \(r = min \{ r_{y_{i}} : 1 \leq i \leq n \} \). We claim that \(B_r(x)\) is contained in \(E^C\). To see why, consider any \(z \in B_r(x)\). \(d(x, y_i) \leq d(x, z) + d(z, y_i)\). Thus, \(d(z, y_i) \geq d(x, y_i) - d(x,z) \geq 2r - r = r\). Thus, since the distance between any \(y_i\) and \(z\) is greater than \(r\), \(z\) cannot be contained in any of the open subsets in the finite cover, and thus \(z\) is not in \(E\) as desired. Thus, \(E^C\) is open, and so \(E\) is closed. 
\end{proof}
\end{thm}

\begin{thm}{}{}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). \newline 
If E is compact, then E is bounded. \newline 

We have not yet defined what it means for a subset to be bounded. %TODO Introduce definition of bounded
Why would compactness imply that E bounded? Certainly, there must be some connection between bounding a subset and having a finite subcover, especially if we are able to bound each of the subsets in the subcover. Similarly to the last proof, we can construct a clever open cover that will allow us to get the desired result easily. (Proof coming later, consider epsilon balls of radius 1 centered at each element of E as an open cover).

\end{thm}

\begin{thm}{}{}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). \newline 
If \(E\) is compact, then \(E\) is sequentially compact. In other words, 
\begin{equation*}
  \textrm{compact \(\implies\) sequentially compact}
\end{equation*}
We will approach this proof by contradiction. We will start by assuming that the compact set \(E\) is not sequentially compact, meaning that there exists some sequence \((a_n) \in E\) which has no convergent subsequence.
This proof will make use of the fact that the following two statements are equivalent for any sequence \((a_n)\) where each \(a_n \in E\): 
\begin{itemize}
  \item \(a \in E\) is a limit of a subsequence of \(a_n\)
  \item  Any epsilon ball centered at \(a\) must contain an infinite amount of points (this follows from the definition of convergence).
\end{itemize}
Thus, if a sequence has no convergent subsequence, then for any point in the subset, there must exist some epsilon ball that contains a finite amount of points in it (as otherwise, a subsequence would converge to this point). Notice that once we have found an epsilon ball that has a finite number of points in it, any smaller epsilon ball centered at the same point must also have a finite number of points in it (you can only lose points in the epsilon ball by decreasing the radius). And now, we can construct a fascinating open cover: since for any element \(x \in E\) we can find an epsilon ball with a finite number of elements within it, we can also shrink this epsilon ball so that \textbf{only} element \(x\) is inside the ball. We know this is possible because once we have an epsilon ball centered at \(x\) with a finite number of elements, we know that there must exist some element in the ball that is closest to \(x\). If we make the radius of the ball smaller than this radius, then the only element left in the ball will be \(x\) itself. We can then put all such epsilon balls into our open cover (where each ball is an open set only containing one element!). Here is the magic: if we assume that \(E\) is compact, that means that this open cover has a finite subcover. By construction, we know this is only possible by including every set in our open cover. Thus, this implies that there are a finite amount of elements in \(E\). We can now finish the proof in a few ways, but one elegant way to view this is as follows: since \(E\) has finitely many values, and each \(a_n \in E\), \(a_n\) also takes on finitely many values. Since there are infinitely many \(a_n\), there must be infinitely many \(a_n\) that take on any given value in \(E\). Thus, we can construct a subsequence of any given value, which clearly converges since the subsequence is constant. This is a contradiction to our original assumption. (Formal proof here)%TODO Insert formal proof here. It follows easily from the above logic


\end{thm}
\begin{thm}{}{}
Let \((S, d)\) be a metric space. Let \(E \subseteq S\). \newline 
\begin{equation*}
  \textrm{\(E\) is sequentially compact \(\implies\) \(E\) is bounded}
\end{equation*}
This proof turns out to be slightly out of scope for now, but the interested reader (myself included, as I soon hope to include the full proof in these notes) should read further online. A proof was provided in lecture, but it relied on two lemmas that were not proven, so the proof did not feel very satisfactory. (I could maybe include this proof in this section as a place holder)
\end{thm}

We are almost ready to prove the Heine-Borel theorem. First, we have to prove two very helpful theorems.\newline

\begin{thm}{}{closed_compact_intersection}
Let \((S, d)\) be a metric space. Let \(E, I \subseteq S\). \newline 
If \(E\) is a closed subset, and \(I\) is a compact subset, then \(E \cap I\) is a compact subset.\newline 

Intuitively, this is saying that if we have a compact set \(I\), and we are considering a closed portion of that compact set (we are taking the intersection of \(I\) with some closed set \(E\), which implies that the portion we are considering is closed because the intersection of any number of closed sets is closed), then that closed portion can also be covered with a finite number of open subsets. We know that we can cover \(I\) with a finite number of open subsets, so we should be able to cover any closed section within \(I\) with a finite number of open subsets as well.
\begin{proof}
Since both \(E\) and \(I\) are closed, \(E \cap I\) is also closed. Consider any open cover of \(E \cap I\), \(\{u_\alpha\}\). It follows that \(\{u_\alpha\} \cup (E \cap I)^C\) is an open cover of \(I\). Because \(I\) is compact, a finite subcover must exist. If \((E \cap I)^C\) is in this finite subcover, we can recover a finite subcover of \(E \cap I\) by removing \((E \cap I)^C\) from the subcover. Otherwise, we have a finite cover of \(E \cap I\) since \(E \cap I \subseteq I\)
\end{proof}

\end{thm}

\begin{thm}{}{}
Let \(F_1 \supseteq F_2 \supseteq F_3 \supseteq \cdots\) be a 'decreasing' sequence of closed, bounded, nonempty subsets of \(\R^k\). Then, \(F := \bigcap_{n=1}^{\infty}F_n\) is closed, bounded, and nonempty.\newline 

Here we use the term decreasing to imply that each subset \(F_n\) is contained within \(F_{n - 1}\). The fact that \(F\) is closed and bounded should be obvious: we saw earlier that the intersection of any number of closed sets is always closed, and clearly if \(F_1\) is bounded, then all sets contained within \(F_1\) must also be bounded by the same bound as \(F_1\). Thus, we just need to show that the intersection is non empty. If this fact seems trivially true, it may be worth to take a moment to stop and think of why so many conditions are required in the theorem statement. For example, is it necessary that we require for each subset \(F_n\) to be closed? Would the same result hold if \(F_n\) was open? If \(F_n\) was unbounded? (Hint: the answer to both is no!).

\begin{proof}
Since each \(F_n\) is nonempty, we pick some \(x_n \in F_n\) for each \(n\). Since \(F_1\) is bounded, we know that there exists a convergent subsequence \((x_{k_n})\) by Bolzano-Weirstraus. Let us say that this subsequence converges to \(x_0\). Consider any \(F_i\). We can construct a new subsequence from \((x_{k_n})\) by taking only the values for which \(x_{k_n} \in F_i\), of which there must be infinitely many. This subsequence must also converge to \(x_0\). Thus, \(x_0\) is a limit point of \(F_i\), and since \(F_i\) is closed, \(F_i\) must contain \(x_0\). Thus, \(x_0 \in F_i\) for all \(i\), and so \( \{x_0\} \subseteq \bigcap_{n=1}^{\infty}F_n\), meaning that the intersection is nonempty.
\end{proof}

\end{thm}


Now, we are finally ready to prove our last major result of this section. \newline

\begin{thm}{}{heine_borel}
Let \((\R^k, d_{std})\) be our metric space. Let \(E \subseteq \R^k\). \newline 
\begin{equation*}
  \textrm{\(E\) is closed and bounded \(\implies E\) is compact}
\end{equation*}
*Note that this is only true in \(\R^k\).\newline 

To approach this proof, we will actually prove the following statement: \newline 
\begin{equation*}
%TODO Expand on definition of k-cell
  \textrm{Let \(I^k = [a_1,b_1] \times [a_2,b_2] \times\cdots\times [a_k, b_k] \subseteq \R^k\). Then, \(I^k\) is compact.} 
\end{equation*}
Here, we call \(I^k\) a 'k-cell'. By definition, \(I^k\) is a cartesian product of \(k\) closed intervals in \(R\). Thus, we can think of a 'k-cell' as a k-dimensional box. Since it is a product of closed intervals, the k-cell is clearly bounded and closed. Finally, we note that for any closed and bounded set \(E \subseteq \R^k\), we can easily construct a k-cell containing \(E\). Thus, if we prove that any k-cell is compact, we will show that any closed and bounded subset \(E \subseteq \R^k\) must also be compact by theorem \ref{thm:closed_compact_intersection} (please review the theorem statements if this is not clear). This proof is much more intuitive when visualized and aided by diagrams. Should this proof be lacking diagrams (I plan to add them later) I highly suggest the reader search for a youtube video on the proof.
\begin{proof}
Assume for sake of contradiction that \(I^k\) is not compact. We can subdivide \(I^k\) into \(2^k\) smaller k-cells (see diagrams/video). Since \(I^k\) is not compact, for any open cover \(\{u_\alpha\}\) of \(I^k\), at least one of these \(2^k\) sub-cells must not be coverable by a finite number of open subsets in the cover. Call this sub-cell \(I^k_1\). We can repeat this procedure on \(I^k_1\) to find another sub-cell contained within \(I^k_1\) that cannot be covered by a finite number of open subsets in the cover, and we can call this sub-cell \(I^k_2\). Now, consider \(\bigcap_{n=1}^{\infty}I^k_n\). This is a decreasing sequence of closed and bounded subsets, and so we know that the intersection is non-empty. Let \(x \in \bigcap_{n=1}^{\infty}I^k_n\). We know that there exists \(\alpha\) such that \(x \in u_\alpha\). Since each \(u_\alpha\) is open, we know that there exists \(r > 0\) such that \(B_r(x) \subseteq u_\alpha\). Let \(\delta\) be the diameter of \(I^k\), and thus the diameter of \(I^k_n = \frac{\delta}{2^n}\). Since the diameter of the sub-cells converges to 0 as \(n\) goes to \(\infty\), we know that there exists \(N\) such that \(n > N \implies \frac{\delta}{2^n} < r\). However, this means that \(I^k_n\) is contained within \(u_\alpha\), which is a finite number of open subsets in the open cover. This is a contradiction, and thus, \(I^k\) is compact. 
\end{proof}


\end{thm}









